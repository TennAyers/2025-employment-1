@{
    ViewData["Title"] = "AR Dashboard System";
}

<style>
    /* 全画面設定と黒背景 */
    header, footer, .navbar { display: none !important; }
    body, html { 
        margin: 0; padding: 0; width: 100%; height: 100%; 
        overflow: hidden; background-color: #050505; 
    }
    main.pb-3 { padding-bottom: 0 !important; }
    .container { max-width: none !important; padding: 0 !important; margin: 0 !important; }

    /* メインコンテナ */
    .dashboard-container {
        position: relative;
        width: 100vw;
        height: 100vh;
        background: #000;
        display: flex;
        justify-content: center;
        align-items: center;
        overflow: hidden;
    }

/* 1. ビデオ（一番奥） */
    #video {
        position: absolute;
        /* 左上固定ではなく、画面中央を基準点にする */
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        
        /* min-widthなどは削除し、JSのサイズ計算に委ねる */
        width: auto;
        height: auto;
        z-index: 1;
    }

    /* 2. キャンバス（ビデオの上） */
    #overlay {
        position: absolute;
        /* ビデオと全く同じ位置（中央）に配置 */
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        
        z-index: 2;
        pointer-events: none;
    }

    /* 3. 操作パネル（最前面） */
    .panel-left, .panel-right {
        z-index: 100; /* キャンバス(2)より確実に手前にする */
        pointer-events: auto; /* パネル内のクリックは有効にする */
    }


</style>

<div class="dashboard-container">
    <script src="https://cdn.jsdelivr.net/npm/@@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
    <script defer src="~/js/face-api.js"></script>

    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay" style="pointer-events: none;"></canvas>

    <div class="panel-left">
        <h3>新規登録</h3>
        
        <div class="input-group">
            <input type="text" id="regName" class="ar-input" placeholder="名前">
            <button class="mic-btn" type="button" onclick="window.startSpeech('regName', this)">🎤</button>
        </div>
        
        <div class="input-group">
            <input type="text" id="regAffiliation" class="ar-input" placeholder="所属">
            <button class="mic-btn" type="button" onclick="window.startSpeech('regAffiliation', this)">🎤</button>
        </div>
        
        <div class="input-group">
            <textarea id="regNotes" class="ar-input" placeholder="メモ" rows="3"></textarea>
            <button class="mic-btn" type="button" onclick="window.startSpeech('regNotes', this)">🎤</button>
        </div>

        <button id="registerButton" class="ar-btn">顔データを登録</button>
        <div id="status" class="status-bar">システム準備完了</div>

        <div style="margin-top: 20px; text-align: center;">
            <a href="/Home/Edit" style="color: #00d4ff; text-decoration: none; font-size: 0.8rem;">
                情報編集画面&gt;
            </a>
        </div>
    </div>

    <div class="panel-right">
        <h3>対象分析</h3>
        
        <div class="info-card">
            <div style="font-size:0.7rem; color:#aaa;">名前</div>
            <div id="detName" style="font-size:1.2rem; font-weight:bold;">スキャン中...</div>
        </div>

        <div class="info-card">
            <div style="font-size:0.7rem; color:#aaa;">所属</div>
            <div id="detAffiliation" style="font-size:1rem;">---</div>
        </div>
        
        <div style="margin-top:15px; border-bottom:1px solid #00ff88; color:#00ff88;">会話ログ</div>
        <div id="logContainer" class="log-container">
            <div style="text-align:center; color:#666; margin-top:20px;">履歴なし</div>
        </div>

        <div id="logInputArea" style="opacity:0.5; pointer-events:none; margin-top:auto;">
            <div class="input-group" style="margin-bottom:5px;">
                <input type="text" id="newLogContent" class="ar-input" placeholder="会話内容...">
                <button class="mic-btn" type="button" onclick="window.startSpeech('newLogContent', this)">🎤</button>
            </div>
            <button id="addLogButton" class="ar-btn" style="padding:10px; font-size:0.8rem;">記録を追加</button>
        </div>
    </div>
</div>

@section Scripts {

    <script>
    // =======================================================
    // 0. グローバル変数・設定
    // =======================================================
    const GEMINI_API_KEY = "AIzaSyACdCeSKwHlLhl55na5Jl23ESUbyFaHOnA"; // ご自身のキーを確認してください

    // DOM要素
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay'); // 顔枠用
    const ctx = canvas.getContext('2d');
    const statusEl = document.getElementById('status');
    const detNameEl = document.getElementById('detName');
    const detAffiliationEl = document.getElementById('detAffiliation');
    const logContainer = document.getElementById('logContainer');
    const logInputArea = document.getElementById('logInputArea');
    const newLogInput = document.getElementById('newLogContent');

    // 指カーソル専用キャンバス（最前面）作成
    const cursorCanvas = document.createElement('canvas');
    const cursorCtx = cursorCanvas.getContext('2d');
    cursorCanvas.id = 'cursor-layer';
    Object.assign(cursorCanvas.style, {
        position: 'absolute', top: '50%', left: '50%',
        transform: 'translate(-50%, -50%)', pointerEvents: 'none', zIndex: '1000'
    });
    document.querySelector('.dashboard-container').appendChild(cursorCanvas);

    // 状態管理変数
    let displaySize = { width: 640, height: 480 };
    let lastDetectedDescriptor = null;
    let currentIdentifiedUserId = null;
    let hands = null;
    let lastHandLandmarks = null;
    let activeRecognition = null;

    // パフォーマンス調整用
    let frameCount = 0;
    let lastDetections = [];
    let isProcessingFace = false;

    // 指カーソル用
    let cursorX = 0, cursorY = 0;
    const SMOOTHING_FACTOR = 0.8;
    let isPinching = false, wasPinching = false;

    // ★ジェスチャー（チェックマーク）用変数
    let gestureCooldown = false;     // 連打防止用
    let lastFocusedInputId = 'newLogContent'; // デフォルトの入力先

    // =======================================================
    // 1. フォーカス追跡 & 音声入力
    // =======================================================
    
    // 入力欄がフォーカスされたら、それを「マイク対象」として記憶する
    window.addEventListener('load', () => {
        const inputs = document.querySelectorAll('input[type="text"], textarea');
        inputs.forEach(input => {
            input.addEventListener('focus', () => {
                lastFocusedInputId = input.id;
            });
            // クリック時もフォーカスとみなす
            input.addEventListener('click', () => {
                lastFocusedInputId = input.id;
            });
        });
    });

    // 音声認識開始・停止関数
    window.startSpeech = function(targetId, btn) {
        // フォーカスを更新
        lastFocusedInputId = targetId;

        if (!('webkitSpeechRecognition' in window)) {
            alert("Chromeブラウザを使用してください。");
            return;
        }

        // 既に起動中なら停止処理
        if (activeRecognition) {
            activeRecognition.stop();
            activeRecognition = null;
            if(btn) btn.classList.remove('listening');
            if (statusEl) statusEl.innerText = "待機中";
            return;
        }

        // 新規開始
        const recognition = new webkitSpeechRecognition();
        recognition.lang = 'ja-JP';
        recognition.interimResults = true;
        const isContinuous = (targetId === 'newLogContent'); // 会話ログのみ連続入力
        recognition.continuous = isContinuous;

        const inputEl = document.getElementById(targetId);
        let baseText = inputEl.value;

        // UI更新
        if(btn) btn.classList.add('listening');
        if (statusEl) {
            statusEl.innerText = isContinuous ? "会話記録中..." : "聞き取り中...";
            statusEl.style.color = isContinuous ? "#ff0055" : "#00d4ff";
        }

        let finalTranscriptBuffer = baseText;
        if (finalTranscriptBuffer && !finalTranscriptBuffer.endsWith(' ')) finalTranscriptBuffer += ' ';

        recognition.onresult = (event) => {
            let interim = '';
            let newFinal = '';
            for (let i = event.resultIndex; i < event.results.length; ++i) {
                if (event.results[i].isFinal) {
                    newFinal += event.results[i][0].transcript;
                } else {
                    interim += event.results[i][0].transcript;
                }
            }
            if (newFinal) {
                finalTranscriptBuffer += newFinal + (isContinuous ? "、" : "");
            }
            inputEl.value = finalTranscriptBuffer + interim;
            inputEl.scrollTop = inputEl.scrollHeight;
        };

        recognition.onend = () => {
            // 自動的に止まった場合の処理
            if (activeRecognition === recognition) {
                activeRecognition = null;
                if(btn) btn.classList.remove('listening');
                if (statusEl) {
                    statusEl.innerText = "待機中";
                    statusEl.style.color = "#aaa";
                }
            }
        };

        activeRecognition = recognition;
        recognition.start();
    };

    // =======================================================
    // 2. モデル読み込み
    // =======================================================
    async function loadModels() {
        try {
            statusEl.innerText = "AIモデル読み込み中...";
            await faceapi.nets.tinyFaceDetector.loadFromUri('/js/models');
            await faceapi.nets.faceLandmark68Net.loadFromUri('/js/models');
            await faceapi.nets.faceRecognitionNet.loadFromUri('/js/models');

            if (typeof Hands === 'undefined') {
                statusEl.innerText = "Handsモデルエラー";
                return false;
            }
            hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@@mediapipe/hands/${file}`});
            hands.setOptions({
                maxNumHands: 1,
                modelComplexity: 1,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });
            hands.onResults(results => {
                lastHandLandmarks = results.multiHandLandmarks && results.multiHandLandmarks.length > 0 
                    ? results.multiHandLandmarks[0] : null;
            });

            console.log("モデル読み込み完了");
            statusEl.innerText = "システム準備完了";
            return true;
        } catch (err) {
            console.error(err);
            statusEl.innerText = "モデル読込エラー";
            return false;
        }
    }

    // =======================================================
    // 3. 画面サイズ管理
    // =======================================================
    async function startVideo() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { width: { ideal: 1280 }, height: { ideal: 720 } } 
            });
            video.srcObject = stream;
        } catch (err) {
            console.error(err);
            statusEl.innerText = "カメラ起動エラー";
        }
    }

    function updateCanvasSize() {
        if (!video.videoWidth) return;
        const wRatio = window.innerWidth / window.innerHeight;
        const vRatio = video.videoWidth / video.videoHeight;
        let w, h;
        if (wRatio > vRatio) { h = window.innerHeight; w = h * vRatio; } 
        else { w = window.innerWidth; h = w / vRatio; }

        video.style.width = `${w}px`; video.style.height = `${h}px`;
        canvas.width = w; canvas.height = h;
        canvas.style.width = `${w}px`; canvas.style.height = `${h}px`;
        cursorCanvas.width = w; cursorCanvas.height = h;
        cursorCanvas.style.width = `${w}px`; cursorCanvas.style.height = `${h}px`;
        displaySize = { width: w, height: h };
        faceapi.matchDimensions(canvas, displaySize);
    }
    window.addEventListener('resize', updateCanvasSize);

    // =======================================================
    // 4. 指の幾何学計算 & ジェスチャー検知
    // =======================================================
    function lerp(start, end, factor) { return start + (end - start) * factor; }
    
    // 2点間の距離を計算
    function dist(p1, p2) {
        return Math.hypot(p1.x - p2.x, p1.y - p2.y);
    }

    // ★チェックマーク(L字)ジェスチャー判定（向き不問）
    function isCheckmarkGesture(landmarks) {
        if (!landmarks) return false;

        const wrist = landmarks[0];
        const thumbTip = landmarks[4];
        const indexTip = landmarks[8];
        const indexMCP = landmarks[5]; // 人差し指の付け根
        
        // 1. スケール（手の大きさ）の基準を作る: 手首から人差し指の付け根までの距離
        const handScale = dist(wrist, indexMCP);
        if (handScale === 0) return false;

        // 2. 中指(12), 薬指(16), 小指(20) が「握られている」か？
        //    判定基準: 指先(Tip)が第二関節(PIP)よりも手首に近いかどうか
        //    PIPインデックス: 中(10), 薬(14), 小(18)
        const foldedFingers = [
            { tip: 12, pip: 10 },
            { tip: 16, pip: 14 },
            { tip: 20, pip: 18 }
        ];

        let areOthersFolded = true;
        for (let f of foldedFingers) {
            const dTip = dist(landmarks[f.tip], wrist);
            const dPip = dist(landmarks[f.pip], wrist);
            // 指先の方が手首に近い、もしくはほぼ同じ位置なら「曲げている」とみなす
            // (少し余裕を持たせるため *1.1)
            if (dTip > dPip * 1.1) {
                areOthersFolded = false; 
                break;
            }
        }
        if (!areOthersFolded) return false;

        // 3. 人差し指が伸びているか？
        //    指先(8)が付け根(5)より手首から遠くにあること
        const dIndexTip = dist(indexTip, wrist);
        const dIndexMCP = dist(indexMCP, wrist);
        if (dIndexTip < dIndexMCP * 1.5) return false; // あまり伸びていない

        // 4. 親指と人差し指が「開いている」か？ (L字チェック)
        //    ピンチ操作（指をつまむ）と区別するため、指先同士の距離が十分離れているか確認
        const tipDistance = dist(thumbTip, indexTip);
        
        // 指先距離が、手のひらサイズ(handScale)より大きければ「開いている」とみなす
        const isLShape = tipDistance > handScale * 0.8;

        return isLShape;
    }

    // 指カーソル処理
    function handleFingerInteraction(landmarks) {
        cursorCtx.clearRect(0, 0, cursorCanvas.width, cursorCanvas.height);
        if (!landmarks) return;

        // カーソル位置計算（人差し指の先）
        const indexTip = landmarks[8];
        const targetX = indexTip.x * cursorCanvas.width;
        const targetY = indexTip.y * cursorCanvas.height;

        if (cursorX === 0 && cursorY === 0) {
            cursorX = targetX; cursorY = targetY;
        } else {
            cursorX = lerp(cursorX, targetX, SMOOTHING_FACTOR);
            cursorY = lerp(cursorY, targetY, SMOOTHING_FACTOR);
        }

        // ピンチ判定（クリック動作）
        const thumbTip = landmarks[4];
        const pinchDist = dist(indexTip, thumbTip);
        isPinching = (pinchDist < 0.05);

        // カーソル描画
        cursorCtx.beginPath();
        cursorCtx.arc(cursorX, cursorY, isPinching ? 10 : 6, 0, 2 * Math.PI);
        cursorCtx.fillStyle = isPinching ? '#ff0055' : '#00d4ff';
        cursorCtx.shadowBlur = 10; cursorCtx.shadowColor = cursorCtx.fillStyle;
        cursorCtx.fill();
        cursorCtx.shadowBlur = 0;
        cursorCtx.strokeStyle = 'white'; cursorCtx.lineWidth = 2; cursorCtx.stroke();

        // 当たり判定 (ピンチ時)
        const rect = cursorCanvas.getBoundingClientRect();
        const screenX = rect.left + cursorX;
        const screenY = rect.top + cursorY;
        const el = document.elementFromPoint(screenX, screenY);

        document.querySelectorAll('.hovered-by-finger').forEach(e => e.classList.remove('hovered-by-finger'));
        if (el) {
            if (['BUTTON', 'INPUT', 'TEXTAREA', 'A'].includes(el.tagName)) {
                el.classList.add('hovered-by-finger');
                // ピンチ開始時のみクリック発火
                if (isPinching && !wasPinching) {
                    el.click();
                    el.focus(); // フォーカスも当てる
                }
            }
        }
        wasPinching = isPinching;
    }

    // ジェスチャー視覚フィードバック
    function showGestureFeedback(text) {
        const div = document.createElement('div');
        div.innerHTML = text; // アイコンなどHTML許可
        Object.assign(div.style, {
            position: 'absolute', left: '50%', top: '40%',
            transform: 'translate(-50%, -50%)', fontSize: '4rem',
            color: '#00ff88', fontWeight: 'bold', textShadow: '0 0 20px #00ff88',
            zIndex: '2000', transition: 'opacity 1s ease-out, top 1s ease-out', pointerEvents: 'none'
        });
        document.body.appendChild(div);

        requestAnimationFrame(() => {
            div.style.opacity = '0';
            div.style.top = '30%';
        });
        setTimeout(() => div.remove(), 1000);
    }

    // =======================================================
    // 5. メインループ
    // =======================================================
    async function detectionLoop() {
        if (!video || video.paused || video.ended) {
            requestAnimationFrame(detectionLoop);
            return;
        }

        // 1. 手の検出
        if (hands) await hands.send({image: video});

        // 2. 顔の検出 (負荷軽減のため4回に1回)
        frameCount++;
        if (frameCount % 4 === 0 && !isProcessingFace) {
            isProcessingFace = true;
            faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                .withFaceLandmarks()
                .withFaceDescriptors()
                .then(detections => {
                    lastDetections = faceapi.resizeResults(detections, displaySize);
                    if (lastDetections.length === 1) {
                        const detection = lastDetections[0];
                        lastDetectedDescriptor = detection.descriptor;
                        // 顔識別API呼び出し
                        fetch('/api/face/identify', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({ Descriptor: JSON.stringify(Array.from(detection.descriptor)) })
                        }).then(r => r.json()).then(res => {
                            if (res.success) {
                                detNameEl.innerText = res.name;
                                detAffiliationEl.innerText = res.affiliation || "なし";
                                updateLogView(res.logs);
                                currentIdentifiedUserId = res.id;
                                logInputArea.style.opacity = "1";
                                logInputArea.style.pointerEvents = "auto";
                            } else {
                                detNameEl.innerText = "未登録の対象";
                                detAffiliationEl.innerText = "---";
                                currentIdentifiedUserId = null;
                                logInputArea.style.opacity = "0.5";
                                logInputArea.style.pointerEvents = "none";
                            }
                        }).catch(() => {});
                    }
                    isProcessingFace = false;
                }).catch(() => { isProcessingFace = false; });
        }

        // 3. 描画 (顔枠)
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        if (lastDetections.length === 1) {
            drawTechBox(lastDetections[0].detection.box);
        }

        // 4. 指カーソル & ジェスチャー処理
        handleFingerInteraction(lastHandLandmarks);

        if (lastHandLandmarks) {
            // ★ チェックマークジェスチャー検知
            if (isCheckmarkGesture(lastHandLandmarks)) {
                if (!gestureCooldown) {
                    gestureCooldown = true;
                    // 誤動作防止のクールダウン (1.5秒)
                    setTimeout(() => { gestureCooldown = false; }, 1500);

                    // 直近でフォーカスした入力欄のマイクボタンを探して押す
                    const targetBtn = document.querySelector(`button[onclick*="'${lastFocusedInputId}'"]`);
                    
                    if (targetBtn) {
                        // ONかOFFか判定してフィードバックを変える
                        const willStart = !targetBtn.classList.contains('listening');
                        const icon = willStart ? '🎙️ ON' : '🔇 OFF';
                        showGestureFeedback(icon);
                        
                        // マイクが現在ON（＝これからOFFにする操作）かつ、対象が会話ログなら自動送信
                        const isTurningOff = targetBtn.classList.contains('listening');
                        const isLogInput = (lastFocusedInputId === 'newLogContent');

                        targetBtn.click(); // まずマイクをOFFにする（停止処理）

                        if (isTurningOff && isLogInput) {
                         // 少し待ってから（音声認識の確定待ち）「記録を追加」ボタンを自動クリック
                         showGestureFeedback("🚀 Auto Submit");
                        setTimeout(() => {
                         document.getElementById('addLogButton').click();
                        }, 1000); 
                    }
                    } else {
                        showGestureFeedback("⚠️ No Input Selected");
                    }
                }
            }
        }

        requestAnimationFrame(detectionLoop);
    }

    // 枠描画ヘルパー
    function drawTechBox(box) {
        const { x, y, width: w, height: h } = box;
        ctx.strokeStyle = '#00d4ff'; ctx.lineWidth = 2;
        ctx.strokeRect(x, y, w, h);
        const lineLen = 20;
        ctx.beginPath();
        ctx.strokeStyle = '#00ff88'; ctx.lineWidth = 4;
        ctx.moveTo(x, y + lineLen); ctx.lineTo(x, y); ctx.lineTo(x + lineLen, y);
        ctx.moveTo(x + w - lineLen, y); ctx.lineTo(x + w, y); ctx.lineTo(x + w, y + lineLen);
        ctx.moveTo(x + w, y + h - lineLen); ctx.lineTo(x + w, y + h); ctx.lineTo(x + w - lineLen, y + h);
        ctx.moveTo(x + lineLen, y + h); ctx.lineTo(x, y + h); ctx.lineTo(x, y + h - lineLen);
        ctx.stroke();
    }

    function updateLogView(logs) {
        if (!logs || logs.length === 0) {
            logContainer.innerHTML = '<div style="text-align:center; color:#666; margin-top:20px;">履歴なし</div>';
            return;
        }
        let html = '';
        logs.forEach(l => {
            const date = new Date(l.date).toLocaleString();
            html += `<div class="log-item"><div class="log-date">${date}</div><div class="log-content">${l.content}</div></div>`;
        });
        logContainer.innerHTML = html;
    }

    // =======================================================
    // 6. Gemini要約 & データ登録
    // =======================================================
    async function summarizeWithGemini(text) {
        if (!GEMINI_API_KEY) { alert("APIキー設定エラー"); return text; }
        const modelName = "gemini-2.5-flash"; 
        const url = `https://generativelanguage.googleapis.com/v1beta/models/${modelName}:generateContent?key=${GEMINI_API_KEY}`;
        const systemPrompt = `
あなたはプロのプロジェクトマネージャーです。以下の会話ログ等のテキストを読み、チーム共有用の「業務日報」として要約してください。
また、相手との会話から得られるその人物の情報も書き出してください
# 制約条件
1. **構成**: 【実施内容】【課題・問題点】【次回アクション】の3見出し。
2. **形式**: 箇条書き。
3. **文体**: ビジネスライク。
4. **長さ**: 300文字以内。
5. **例外**: 重要な個人情報は残すこと。
# 対象テキスト
${text}`;

        try {
            const response = await fetch(url, {
                method: 'POST', headers: { 'Content-Type': 'application/json' }, 
                body: JSON.stringify({ contents: [{ parts: [{ text: systemPrompt }] }] })
            });
            const data = await response.json();
            if (data.candidates && data.candidates[0].content) {
                return data.candidates[0].content.parts[0].text;
            } else { return text; }
        } catch (error) { console.error(error); return text; }
    }

    // イベント登録
    startVideo();
    video.addEventListener('loadedmetadata', () => {
        updateCanvasSize();
        video.play();
    });
    video.addEventListener('play', async () => {
        const loaded = await loadModels();
        if (loaded) requestAnimationFrame(detectionLoop);
    });

    document.getElementById('registerButton').addEventListener('click', async () => {
        if (!lastDetectedDescriptor) { alert("顔未検出"); return; }
        const data = {
            Name: document.getElementById('regName').value,
            Affiliation: document.getElementById('regAffiliation').value,
            Notes: document.getElementById('regNotes').value,
            FaceDescriptorJson: JSON.stringify(Array.from(lastDetectedDescriptor)) 
        };
        try {
            const res = await fetch('/api/face/register', {
                method: 'POST', headers: {'Content-Type': 'application/json'},
                body: JSON.stringify(data)
            });
            const result = await res.json();
            if(result.success) {
                alert("登録完了");
                document.getElementById('regName').value = "";
                document.getElementById('regAffiliation').value = "";
                document.getElementById('regNotes').value = "";
            } else { alert("エラー: " + result.message); }
        } catch(e) {}
    });

    document.getElementById('addLogButton').addEventListener('click', async () => {
        if (activeRecognition) { activeRecognition.stop(); }
        const originalContent = newLogInput.value;
        if (!currentIdentifiedUserId || !originalContent) { alert("対象認識または入力不足"); return; }

        const btn = document.getElementById('addLogButton');
        btn.innerText = "AI処理中..."; btn.disabled = true;
        try {
            const summarizedText = await summarizeWithGemini(originalContent);
            await fetch('/api/face/add_log', {
                method: 'POST', headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({ FaceId: currentIdentifiedUserId, Content: summarizedText })
            });
            const date = new Date().toLocaleString();
            logContainer.insertAdjacentHTML('afterbegin', 
                `<div class="log-item" style="border-left:3px solid #ff0055;padding-left:5px;"><div class="log-date">${date}</div><div class="log-content">${summarizedText}</div></div>`);
            newLogInput.value = "";
        } catch(e) { console.error(e); } 
        finally { btn.innerText = "記録を追加"; btn.disabled = false; }
    });
</script>
}